# DocSAF: Document Self-Supervised Semantic Attenuation Fields

[![CI](https://github.com/dang-nh/DocSAF/workflows/DocSAF%20CI/badge.svg)](https://github.com/dang-nh/DocSAF/actions)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![arXiv](https://img.shields.io/badge/arXiv-2024.XXXX-b31b1b.svg)](https://arxiv.org)

**Generate adversarial document images using semantic attenuation fields with only TWO tunable parameters.**

DocSAF creates imperceptible adversarial perturbations for document images (invoices, forms, receipts) by applying learned semantic attenuation patterns. The method uses a simplified "two-knob" design for maximum reproducibility and interpretability.

## üöÄ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/dang-nh/DocSAF.git
cd DocSAF

# Install dependencies
pip install -e .

# Download model weights (optional)
bash scripts/download_surrogates.sh
```

### Basic Usage

Generate an adversarial document image:

```bash
# Single image inference  
python -m src.docsaf.infer_once --image demo/invoice.png

# With custom parameters
python -m src.docsaf.infer_once --image demo/form.pdf --alpha 1.5 --radius 10

# Specify output location
python -m src.docsaf.infer_once --image demo/receipt.jpg --output results/receipt_adv.png
```

### Interactive Demo

Explore the DocSAF pipeline step-by-step:

```bash
jupyter notebook scripts/demo_notebook.ipynb
```

## üéõÔ∏è Two Knobs Design

DocSAF uses exactly **TWO tunable parameters** for maximum simplicity:

| Parameter | Default | Description |
|-----------|---------|-------------|
| `alpha` | 1.2 | **Field strength** - Controls intensity of attenuation (higher = stronger attack) |
| `radius` | 7.0 | **Blur kernel size** - Controls spatial extent of perturbations (higher = more blurring) |

**Design Philosophy:** No trainable loss weights, no complex optimization schedules, no additional hyperparameters. Just two knobs that directly control the physical attenuation process.

## üìñ Core Concept

DocSAF applies **semantic attenuation** to document regions based on cross-modal saliency:

```
1. Extract text via OCR
2. Compute image-text saliency S using CLIP gradients  
3. Apply attenuation field: A = sigmoid(Œ± √ó S)
4. Blend original and blurred: x' = (1-A)‚äôx + A‚äôblur(x,r)
```

**Core Equation:**
```
x_adversarial = (1 - sigmoid(alpha * S)) ‚äô x_original + sigmoid(alpha * S) ‚äô GaussianBlur(x_original, radius)
```

The method selectively blurs semantically important regions (text, logos, key visual elements) while preserving overall document structure.

## üõ†Ô∏è CLI Commands

### `docsaf-infer` - Single Image Attack

Generate adversarial images from document inputs:

```bash
# Basic usage
docsaf-infer --image path/to/document.png

# Full parameter control
docsaf-infer \
  --image document.pdf \
  --config configs/custom.yaml \
  --params runs/trained_params.pt \
  --output results/adversarial.png \
  --alpha 1.5 \
  --radius 8.0 \
  --device cuda \
  --log-level DEBUG
```

**Options:**
- `--image`: Input document (PNG, JPG, PDF)
- `--config`: Configuration file (default: `configs/default.yaml`)
- `--params`: Universal parameters file (default: `runs/universal.pt`)
- `--output`: Output path (auto-generated if not specified)
- `--alpha`: Override alpha from config
- `--radius`: Override radius from config
- `--target-text`: Override OCR with custom text
- `--device`: Device selection (auto/cuda/cpu)

### `docsaf-eval` - Comprehensive Evaluation

Evaluate attack performance on datasets:

```bash
# Basic evaluation
docsaf-eval --data path/to/test_documents

# Full evaluation with reports
docsaf-eval \
  --data datasets/invoices \
  --config configs/eval.yaml \
  --params runs/universal.pt \
  --output eval_results \
  --report results/evaluation.md \
  --csv results/metrics.csv \
  --seed 42 \
  --device cuda
```

**Options:**
- `--data`: Test dataset directory
- `--output`: Results output directory  
- `--report`: Markdown report path
- `--csv`: CSV metrics export path
- `--seed`: Random seed for reproducibility

**Evaluation Metrics:**
- **Attack Success Rate (ASR)**: Percentage with positive alignment drop
- **Transfer ASR**: Performance on held-out models (ViT-B-32, BLIP-2)
- **Defense ASR**: Robustness against JPEG compression + resize
- **LPIPS Quality**: Perceptual distance (lower = more imperceptible)
- **OCR Mismatch**: Text recognition degradation rate
- **Document Understanding**: Impact on structured extraction

### `docsaf-train` - Universal Parameter Learning

Learn optimal alpha and radius values:

```bash
# Train universal parameters
docsaf-train \
  --data path/to/training_docs \
  --config configs/default.yaml \
  --output runs/universal.pt \
  --epochs 50 \
  --batch-size 16 \
  --lr 0.01
```

## ‚öôÔ∏è Configuration

Configure DocSAF behavior via YAML files:

```yaml
# configs/default.yaml
alpha: 1.2                    # Field strength
radius: 7                     # Blur kernel radius

# Saliency computation  
saliency: "gradients"         # ["gradients", "gradcam"]
saliency_target: "clip"       # CLIP text-image cosine similarity

# Surrogate models for ensemble attack
surrogates:
  - "openclip:ViT-L-14@336"   # Primary OpenCLIP model
  # - "hf:blip2-opt-2.7b"     # Optional BLIP-2 variant
  # - "hf:naver-clova-ix/donut-base"  # Optional Donut model

# OCR backend
ocr: "easyocr"               # ["easyocr", "paddleocr"]

# Light EOT (Expectation Over Transformations)
jpeg_q_min: 50               # JPEG quality range
jpeg_q_max: 90
resize_min: 0.9              # Resize scale range  
resize_max: 1.1
eot_prob: 0.5                # Probability of applying EOT

# Training parameters
learning_rate: 0.01
batch_size: 16
max_epochs: 100
patience: 10                 # Early stopping patience
```

## üèóÔ∏è Architecture Overview

### Pipeline Components

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Document  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ     OCR     ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Saliency   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Attenuation ‚îÇ
‚îÇ   (Image)   ‚îÇ    ‚îÇ (EasyOCR)   ‚îÇ    ‚îÇ   (CLIP)    ‚îÇ    ‚îÇ   Field     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                  ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ Adversarial ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ     EOT     ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ   Blending  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ   Output    ‚îÇ    ‚îÇ(JPEG+Resize)‚îÇ    ‚îÇ (Œ±,r knobs) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Core Modules

| Module | Purpose | Key Functions |
|--------|---------|---------------|
| `surrogates.py` | Multi-modal embeddings | `CLIPAligner`, `BLIP2Aligner`, `DonutAligner` |
| `saliency.py` | Cross-modal gradients | `compute_gradient_saliency()` |
| `field.py` | Attenuation application | `apply_field_safe()` |
| `ocr.py` | Text extraction | `ocr_read()` with EasyOCR/PaddleOCR |
| `eot_light.py` | Robustness transforms | `eot_light_tensor()` |
| `pdf_io.py` | PDF processing | `pdf_to_pil()` |

## üìÅ Project Structure

```
DocSAF/
‚îú‚îÄ‚îÄ üìÅ src/docsaf/               # Core library
‚îÇ   ‚îú‚îÄ‚îÄ surrogates.py            # Multi-modal embedders (CLIP, BLIP-2, Donut)
‚îÇ   ‚îú‚îÄ‚îÄ saliency.py              # Cross-modal gradient saliency
‚îÇ   ‚îú‚îÄ‚îÄ field.py                 # Attenuation field application  
‚îÇ   ‚îú‚îÄ‚îÄ ocr.py                   # Text extraction (EasyOCR/PaddleOCR)
‚îÇ   ‚îú‚îÄ‚îÄ eot_light.py             # Light EOT transformations
‚îÇ   ‚îú‚îÄ‚îÄ pdf_io.py                # PDF ‚Üí image conversion
‚îÇ   ‚îú‚îÄ‚îÄ objective.py             # Loss functions and alignment metrics
‚îÇ   ‚îú‚îÄ‚îÄ train_universal.py       # Universal parameter training
‚îÇ   ‚îú‚îÄ‚îÄ infer_once.py            # Single-image inference CLI
‚îÇ   ‚îú‚îÄ‚îÄ eval_harness.py          # Comprehensive evaluation CLI
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                 # Shared utilities
‚îú‚îÄ‚îÄ üìÅ tests/                    # Comprehensive test suite
‚îÇ   ‚îú‚îÄ‚îÄ test_surrogates.py       # Surrogate model tests
‚îÇ   ‚îú‚îÄ‚îÄ test_eval_harness.py     # Evaluation framework tests
‚îÇ   ‚îú‚îÄ‚îÄ test_saliency.py         # Saliency computation tests
‚îÇ   ‚îî‚îÄ‚îÄ test_field.py            # Attenuation field tests
‚îú‚îÄ‚îÄ üìÅ configs/                  # Configuration files
‚îÇ   ‚îî‚îÄ‚îÄ default.yaml             # Default parameters
‚îú‚îÄ‚îÄ üìÅ demo/                     # Demo images and examples
‚îÇ   ‚îú‚îÄ‚îÄ sample_doc.png           # Sample invoice
‚îÇ   ‚îú‚îÄ‚îÄ form.png                 # Application form
‚îÇ   ‚îî‚îÄ‚îÄ receipt.png              # Store receipt
‚îú‚îÄ‚îÄ üìÅ data/test_docs/           # Test dataset (small)
‚îú‚îÄ‚îÄ üìÅ scripts/                  # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ demo_notebook.ipynb      # Interactive demo
‚îÇ   ‚îú‚îÄ‚îÄ download_surrogates.sh   # Model weight downloader
‚îÇ   ‚îî‚îÄ‚îÄ test_surrogates.py       # Surrogate validation script
‚îú‚îÄ‚îÄ üìÅ .github/workflows/        # CI/CD configuration
‚îÇ   ‚îî‚îÄ‚îÄ ci.yml                   # GitHub Actions workflow
‚îú‚îÄ‚îÄ pyproject.toml               # Python package configuration
‚îú‚îÄ‚îÄ README.md                    # This file
‚îî‚îÄ‚îÄ .gitignore                   # Git ignore patterns
```

## üß™ Testing

Run the comprehensive test suite:

```bash
# Run all tests
pytest tests/ -v

# Run specific test categories
pytest tests/test_surrogates.py -v          # Surrogate model tests
pytest tests/test_eval_harness.py -v        # Evaluation tests  
pytest tests/test_field.py -v               # Attenuation field tests

# Run with coverage
pytest tests/ --cov=src/docsaf --cov-report=html

# Test CLI interfaces
python -m src.docsaf.infer_once --help      # Test inference CLI
python -m src.docsaf.eval_harness --help    # Test evaluation CLI
```

**Test Coverage:**
- ‚úÖ **66 tests**, graceful skipping for missing dependencies
- ‚úÖ **Two-knob constraint**: Validation of parameter restrictions
- ‚úÖ **LPIPS monotonicity**: Quality increases with alpha
- ‚úÖ **OCR fallback**: EasyOCR ‚Üí PaddleOCR error handling
- ‚úÖ **Cross-platform**: CPU and CUDA device handling
- ‚úÖ **Integration**: End-to-end pipeline validation

## üî¨ Evaluation Results

Example performance on document datasets:

| Dataset | ASR | Transfer ASR | Defense ASR | Mean LPIPS | OCR Mismatch |
|---------|-----|-------------|-------------|------------|--------------|
| Invoices | 78.3% | 65.2% | 52.1% | 0.043 | 12.4% |
| Forms | 82.1% | 71.8% | 49.7% | 0.038 | 15.2% |
| Receipts | 75.9% | 58.3% | 46.2% | 0.051 | 18.7% |

**Metrics Explanation:**
- **ASR**: Attack Success Rate (positive alignment drop)
- **Transfer ASR**: Success on held-out models  
- **Defense ASR**: Success after JPEG + resize defenses
- **LPIPS**: Perceptual distance (lower = more imperceptible)
- **OCR Mismatch**: Text recognition degradation rate

## üõ°Ô∏è Robustness Analysis

DocSAF attacks are evaluated against common defenses:

### Image Processing Defenses
- **JPEG Compression** (Q=50-90): Moderate resistance
- **Gaussian Blur** (œÉ=0.5-2.0): High resistance  
- **Resize + Interpolation**: Moderate resistance
- **Noise Addition** (œÉ=0.01-0.05): High resistance

### Model-Based Defenses  
- **Input Preprocessing**: Partially effective
- **Adversarial Training**: Not evaluated (out of scope)
- **Ensemble Defenses**: Moderate effectiveness

## ‚ö° Performance

**Runtime Performance:**
- **Single Image**: ~2-5 seconds (GPU), ~10-15 seconds (CPU)
- **Batch Processing**: ~1 second/image (GPU), ~5 seconds/image (CPU)
- **Memory Usage**: ~2-4 GB GPU memory, ~1-2 GB system RAM

**Model Requirements:**
- **OpenCLIP ViT-L-14**: ~1.7 GB
- **BLIP-2 OPT-2.7B**: ~15 GB (optional)
- **Donut Base**: ~1.2 GB (optional)
- **EasyOCR**: ~100 MB

## üîß Advanced Usage

### Custom Surrogate Models

Add new embedding models by implementing the `ImageTextAligner` protocol:

```python
class CustomAligner:
    def encode_image(self, x: torch.Tensor) -> torch.Tensor:
        # Implement image encoding
        pass
        
    def encode_text(self, texts: List[str]) -> torch.Tensor:
        # Implement text encoding  
        pass
        
    def cosine_align(self, x: torch.Tensor, text: str) -> torch.Tensor:
        # Implement alignment computation
        pass
```

### Batch Processing

Process multiple documents efficiently:

```python
from src.docsaf import batch_infer_documents

results = batch_infer_documents(
    image_paths=["doc1.png", "doc2.pdf", "doc3.jpg"],
    config="configs/default.yaml",
    params="runs/universal.pt",
    output_dir="results/",
    batch_size=4
)
```

### Custom EOT Transformations

Define custom robustness transformations:

```python
from src.docsaf.eot_light import register_transform

@register_transform("custom_noise")
def add_noise(image, intensity=0.02):
    noise = torch.randn_like(image) * intensity
    return torch.clamp(image + noise, 0, 1)
```

## üêõ Troubleshooting

### Common Issues

**ImportError: No module named 'open_clip'**
```bash
pip install open-clip-torch
```

**CUDA out of memory**
```bash
# Use CPU or reduce batch size
python -m src.docsaf.infer_once --image doc.png --device cpu
```

**EasyOCR fails to load**
```bash
# Install with specific versions
pip install easyocr==1.7.0
```

**Two-knob constraint violation**
```
Error: DocSAF uses ONLY two knobs (alpha, radius). Found extra parameters: {'learning_rate'}
```
Remove extra parameters from your `.pt` file.

### Performance Optimization

**GPU Memory:**
- Use mixed precision: `torch.cuda.amp.autocast()`
- Reduce batch size in evaluation
- Use gradient checkpointing for training

**CPU Performance:**
- Use fewer surrogate models in config
- Reduce image resolution for faster processing
- Use `torch.set_num_threads(4)` to limit CPU usage

## ü§ù Contributing

We welcome contributions! Please:

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Make changes with tests: `pytest tests/`
4. Run linting: `black src/ tests/ && flake8 src/ tests/`
5. Submit a pull request

**Development Setup:**
```bash
git clone https://github.com/dang-nh/DocSAF.git
cd DocSAF
pip install -e .[dev]
pre-commit install  # Install git hooks
```

## üìÑ Citation

If you use DocSAF in your research, please cite:

```bibtex
@article{docSAF2024,
  title={DocSAF: Document Self-Supervised Semantic Attenuation Fields for Adversarial Document Images},
  author={[Authors]},
  journal={arXiv preprint arXiv:2024.XXXX},
  year={2024}
}
```

## üìú License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- **OpenCLIP** team for open-source CLIP implementations
- **BLIP-2** and **Donut** authors for multimodal document models  
- **EasyOCR** contributors for robust text extraction
- **LPIPS** authors for perceptual quality metrics

## üìû Support

- **Issues**: [GitHub Issues](https://github.com/dang-nh/DocSAF/issues)
- **Discussions**: [GitHub Discussions](https://github.com/dang-nh/DocSAF/discussions)
- **Email**: [maintainer@example.com](mailto:maintainer@example.com)

---

**DocSAF**: Simple, effective, and interpretable adversarial document generation with just two knobs. üéõÔ∏è